from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from joblib import dump
import matplotlib.pyplot as plt
import numpy as np

def main():
    print("=== ENTRENADOR DE CLASIFICADOR ===")
    print()
    
    # Obtenidos del generador de descriptores
    X = [
        [8.01944495e-01, 5.50914485e-01, 1.54061991e-01, 1.25761228e-01, 1.75050737e-02, 9.33326389e-02, 7.47744585e-05],
        [5.55313611e-01, 2.46740162e-01, 2.16159393e-02, 1.64287598e-02, 3.09590485e-04, 8.16061465e-03, -1.70961580e-06],
        [6.86068493e-01, 3.92413885e-01, 7.62491870e-02, 6.20561204e-02, 4.26866885e-03, 3.88709677e-02, 1.31971719e-05],
        [6.70198298e-01, 3.71572307e-01, 8.00707466e-02, 6.55291866e-02, 4.74663848e-03, 3.99356406e-02, -1.74924329e-05],
        [8.72497083e-01, 6.61363621e-01, 5.95972776e-02, 5.33738060e-02, 3.01016409e-03, 4.31715560e-02, -2.52672348e-05],
        [7.56562541e-01, 4.92969109e-01, 1.16462389e-02, 1.03568904e-02, 1.13746190e-04, 7.26947773e-03, -5.98236522e-08],
        [8.13649286e-01, 5.78395346e-01, 7.68573483e-03, 7.50751505e-03, 5.70197453e-05, 5.63872134e-03, -9.61547498e-07],
        [7.92960520e-01, 5.50740800e-01, 9.01194073e-03, 8.58076962e-03, 7.54568174e-05, 6.36051313e-03, 3.35113307e-08],
        [7.25871417e-01, 4.50952430e-01, 6.25079862e-02, 5.22656953e-02, 2.98739595e-03, 3.50979629e-02, -1.63149488e-06],
        [6.97313259e-01, 4.10305900e-01, 6.30817552e-02, 5.28165627e-02, 3.04864514e-03, 3.38289517e-02, -2.99530487e-06],
        [6.90252571e-01, 4.04928006e-01, 4.68166329e-02, 3.84398684e-02, 1.63069470e-03, 2.44602593e-02, -1.80989782e-06],
        [6.93537348e-01, 4.10236489e-01, 5.08419644e-02, 4.23057083e-02, 1.96204780e-03, 2.70962602e-02, 7.71348791e-07],
        [7.01618009e-01, 4.15720135e-01, 4.79290926e-02, 3.93301829e-02, 1.70760483e-03, 2.53564267e-02, 3.97641189e-06],
        [7.11211125e-01, 4.28562053e-01, 4.58482796e-02, 3.77209360e-02, 1.56868131e-03, 2.46935774e-02, 2.35739145e-06],
        [7.61841945e-01, 4.99602246e-01, 4.64958792e-02, 3.90332652e-02, 1.66286519e-03, 2.75863347e-02, -5.65660650e-06],
        [7.65968797e-01, 5.07842994e-01, 2.43666063e-02, 2.08219611e-02, 4.69006083e-04, 1.48352352e-02, 1.23027974e-06],
        [6.84443696e-01, 3.95403699e-01, 5.47277017e-02, 4.26601190e-02, 2.06124435e-03, 2.68243473e-02, 1.18869521e-05],
        [5.11219114e-01, 1.19259727e-01, 1.42768464e-01, 5.15941083e-02, 4.20071986e-03, 1.57112013e-02, -1.40068628e-03],
        [7.61316445e-01, 4.97501078e-01, 7.56079673e-03, 4.71599121e-03, 2.81491146e-05, 3.24477575e-03, -8.07277679e-07],
        [6.88938826e-01, 4.00294258e-01, 2.34226775e-02, 1.89098437e-02, 3.97968488e-04, 1.19639278e-02, 1.04311956e-06],
        [6.30253612e-01, 3.31401228e-01, 1.95690469e-02, 1.54000764e-02, 2.67336664e-04, 8.86091477e-03, 1.87021542e-06],
        [3.92729224e-01, 1.48374438e-02, 5.76770796e-02, 7.55003809e-03, 1.53866864e-04, 7.66272455e-04, -3.38789558e-05],
        [5.57854189e-01, 2.54101881e-01, 1.07398422e-02, 7.80719020e-03, 7.14887730e-05, 3.93452010e-03, 2.76423074e-07],
        [6.33746219e-01, 3.31988611e-01, 1.77204360e-02, 1.29961700e-02, 1.97191185e-04, 7.48343459e-03, -3.61034444e-06],
        [2.90518501e-01, 2.73792555e-02, 9.07428770e-03, 7.33006795e-04, -5.61039378e-07, 7.85077524e-05, 1.80529407e-06],
        
        [1.59862243e-01, 2.06809583e-04, 1.62235273e-06, 3.64459927e-09, 1.53869324e-18, 1.15748476e-12, -2.80246870e-16],
        [1.59994173e-01, 2.20751831e-04, 3.80159681e-07, 3.00242787e-09, -9.48935312e-17, -4.21523909e-11, -3.58394999e-17],
        [1.60109994e-01, 2.57284477e-04, 3.66253127e-07, 1.61742839e-09, -3.75316455e-17, -1.70820122e-11, 1.18788606e-17],
        [1.59491571e-01, 8.56593102e-05, 2.08622711e-07, 3.40851605e-11, -7.51025034e-20, -1.89206717e-13, -5.11965761e-20],
        [1.59516761e-01, 8.93349850e-05, 2.11210525e-07, 1.76155102e-11, -3.28072653e-20, -1.21978617e-13, -8.84323125e-21],
        [1.59946655e-01, 2.07066358e-04, 9.00166716e-07, 4.23443688e-09, -2.57169510e-16, -5.92832283e-11, -4.70036760e-17],
        [1.65372411e-01, 3.29370236e-04, 3.82683844e-05, 6.70489940e-06, 2.31279724e-11, 9.96870590e-09, 1.04881262e-10],
        [1.59828164e-01, 1.69325349e-04, 3.15779760e-06, 1.07897044e-08, -1.82336439e-17, 3.65613855e-13, -1.99153647e-15],
        [1.59883915e-01, 2.00857024e-04, 1.95350796e-06, 5.41363076e-09, 1.01921394e-16, 2.67311998e-11, -5.47315716e-16],
        [1.59713974e-01, 1.61313525e-04, 6.27791183e-07, 8.26611636e-10, -1.37757664e-17, -8.84013052e-12, 1.28379424e-17],
        [1.59646954e-01, 1.35440158e-04, 1.90683314e-07, 1.87332299e-10, 8.59586862e-19, 2.69373501e-13, 7.17416525e-19],
        [1.60477586e-01, 1.70465111e-04, 6.83962165e-06, 2.65119954e-08, 9.61859621e-15, 3.05530619e-10, -5.91086497e-15],
        [1.64191641e-01, 5.09877463e-04, 4.14257604e-05, 4.73141430e-06, 4.61212962e-11, 4.31068814e-08, 4.75456798e-11],
        [1.60793576e-01, 5.09936437e-06, 6.67095564e-06, 2.86685931e-07, -1.50434009e-14, 4.85368078e-10, -3.96178348e-13],
        [1.59380037e-01, 4.29004071e-05, 3.01424881e-07, 2.61437753e-10, 2.05269791e-18, 4.55564818e-13, 1.08288978e-18],
        [1.20091531e+00, 1.27246830e+00, 3.51056028e-03, 1.95851473e-02, 1.58772358e-04, 2.19280388e-02, -3.41201105e-05],

        [4.32986498e-01, 7.36125125e-02, 5.05918915e-02, 1.01165664e-02, 2.24488792e-04, 2.73538549e-03, 4.45709709e-05],
        [3.34456586e-01, 5.96883800e-02, 3.39610440e-02, 1.63546154e-02, 3.85424512e-04, 3.99503182e-03, -2.82768640e-06],
        [3.71257852e-01, 8.18431614e-02, 4.19132824e-02, 2.08302448e-02, 6.15408491e-04, 5.95072417e-03, 9.69762484e-06],
        [4.22172962e-01, 6.19465397e-02, 4.92118783e-02, 7.64671005e-03, 1.48065985e-04, 1.88348770e-03, 8.94805046e-06],
        [4.05849609e-01, 6.48655451e-02, 4.51168355e-02, 9.55600894e-03, 1.98315638e-04, 2.42102164e-03, 6.41614259e-06],
        [4.36458178e-01, 8.07322939e-02, 4.93632399e-02, 1.01872074e-02, 2.26562800e-04, 2.89453489e-03, 2.92764671e-05],
        [4.71435906e-01, 9.85562499e-02, 5.31208909e-02, 8.84724037e-03, 1.90151732e-04, 2.77111830e-03, -2.50768667e-05],
        [4.39543128e-01, 7.44889220e-02, 5.04344711e-02, 1.02882730e-02, 2.25796350e-04, 2.80403211e-03, 6.27621893e-05],
        [3.75771970e-01, 5.67683840e-02, 3.86277495e-02, 9.15293591e-03, 1.72048608e-04, 2.18074178e-03, -4.35633843e-06],
        [3.62426367e-01, 7.87589761e-02, 3.62732663e-02, 1.77997844e-02, 4.52268698e-04, 4.99209832e-03, 4.22096527e-06],
        [3.39584939e-01, 6.61950640e-02, 3.18267854e-02, 1.60573816e-02, 3.63000912e-04, 4.13126743e-03, 6.81346010e-07],
        [3.44684241e-01, 6.79099714e-02, 3.37886006e-02, 1.73938318e-02, 4.21667774e-04, 4.53234677e-03, -2.49295910e-06],
        [3.43778846e-01, 6.74291379e-02, 3.34804004e-02, 1.72160061e-02, 4.13321304e-04, 4.47015503e-03, -2.19854322e-06],
        [3.02615145e-01, 4.14802537e-02, 2.40362920e-02, 9.31787549e-03, 1.39220469e-04, 1.87140777e-03, -7.94475338e-06],
        [3.55432222e-01, 7.25565821e-02, 3.43749444e-02, 1.58772460e-02, 3.70836522e-04, 4.27302743e-03, 8.00909485e-06],
        [3.55308326e-01, 7.24691649e-02, 3.43370829e-02, 1.58485230e-02, 3.69627592e-04, 4.26278303e-03, 7.95301750e-06],
        [3.14150596e-01, 4.82195156e-02, 2.35262046e-02, 8.94119379e-03, 1.29611612e-04, 1.95805896e-03, 4.17586615e-06],
        [3.23958105e-01, 5.46708828e-02, 2.68483578e-02, 1.14201218e-02, 1.99952963e-04, 2.66954223e-03, 2.61461826e-06],
        [3.90106082e-01, 3.35125767e-02, 4.50275597e-02, 5.36510111e-03, 8.32042220e-05, 9.73598734e-04, -5.54044299e-06],
    ]
    
    Y = [ 1,1,1, 1,1, 1, 1,1, 1, 1,1, 1, 1,1, 1, 1,1,1, 1,1,1, 1,1,1,1, 2, 2,2, 2, 2,2, 2, 2,2, 2, 2,2, 2, 2,2,2,3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]

    etiquetas = {1: "llave", 2: "moneda", 3: "tijera"}
    
    print(f"Dataset cargado: {len(X)} muestras, {len(set(Y))} clases")
    print("Distribución por clase:")
    for label in sorted(set(Y)):
        count = Y.count(label)
        print(f"  {label} ({etiquetas[label]}): {count} muestras")
    print()
    
    X = np.array(X)
    Y = np.array(Y)
    
    X_train, X_test, Y_train, Y_test = train_test_split(
        X, Y, test_size=0.2, random_state=42, stratify=Y
    )
    
    print(f"Datos de entrenamiento: {len(X_train)} muestras")
    print(f"Datos de prueba: {len(X_test)} muestras")
    print()
    
    print("Entrenando Decision Tree...")
    clasificador = tree.DecisionTreeClassifier(
        random_state=42,
        max_depth=10,  
        min_samples_split=2,
        min_samples_leaf=1
    )
    clasificador.fit(X_train, Y_train)
    Y_train_pred = clasificador.predict(X_train)
    train_accuracy = accuracy_score(Y_train, Y_train_pred)
    

    Y_test_pred = clasificador.predict(X_test)
    test_accuracy = accuracy_score(Y_test, Y_test_pred)
    
    print(f"Precisión en entrenamiento: {train_accuracy:.3f}")
    print(f"Precisión en prueba: {test_accuracy:.3f}")
    print()
    
    print("Reporte de clasificación (datos de prueba):")
    target_names = [etiquetas[i] for i in sorted(etiquetas.keys())]
    print(classification_report(Y_test, Y_test_pred, target_names=target_names))
    
    plt.figure(figsize=(20, 10))
    tree.plot_tree(clasificador, 
                   feature_names=[f'Hu{i+1}' for i in range(7)],
                   class_names=target_names,
                   filled=True, 
                   fontsize=10)
    plt.title("Árbol de Decisión Entrenado")
    plt.savefig('decision_tree.png', dpi=300, bbox_inches='tight')
    print("Árbol guardado en 'decision_tree.png'")
    plt.show()
    
    modelo_filename = 'clasificador_formas.joblib'
    dump(clasificador, modelo_filename)
    print(f"Modelo guardado en '{modelo_filename}'")
    print()
    
    from joblib import load
    clasificador_cargado = load(modelo_filename)
    print("✓ Modelo verificado - se puede cargar correctamente")
    
    print("\nEjemplo de uso del modelo:")
    ejemplo = X[0:1] 
    prediccion = clasificador_cargado.predict(ejemplo)
    probabilidades = clasificador_cargado.predict_proba(ejemplo)
    
    print(f"Muestra ejemplo: {ejemplo[0]}")
    print(f"Predicción: {prediccion[0]} ({etiquetas[prediccion[0]]})")
    print(f"Probabilidades: {probabilidades[0]}")

if __name__ == "__main__":
    main()